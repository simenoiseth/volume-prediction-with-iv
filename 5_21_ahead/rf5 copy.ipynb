{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "# =====================================================\n",
    "# 1) LOAD DATA\n",
    "# =====================================================\n",
    "train = pd.read_csv(\"5_21_train.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"5_21_test.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Ensure sorted order\n",
    "train = train.sort_values(\"date\").reset_index(drop=True)\n",
    "test  = test.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Combine to build lag features correctly across split\n",
    "split_date = test[\"date\"].min()\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2) FEATURE ENGINEERING (NO DATA LEAKAGE)\n",
    "# =====================================================\n",
    "# --- Time features ---\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"dayofweek\"] = df[\"date\"].dt.dayofweek\n",
    "\n",
    "# vix lag\n",
    "df[\"vix_lag1\"] = df[\"vix_close\"].shift(1)\n",
    "df[\"vix_change\"] = df[\"vix_close\"] - df[\"vix_lag1\"]\n",
    "\n",
    "# --- Volume features (use only known values ≤ t) ---\n",
    "df[\"log_vol\"] = np.log(df[\"sh_volume\"])\n",
    "df[\"vol_lag1_log\"] = np.log(df[\"sh_volume\"].shift(1))\n",
    "df[\"vol_lag2_log\"] = np.log(df[\"sh_volume\"].shift(2))\n",
    "df[\"vol_lag3_log\"] = np.log(df[\"sh_volume\"].shift(3))\n",
    "df[\"vol_lag4_log\"] = np.log(df[\"sh_volume\"].shift(4))   \n",
    "df[\"vol_lag5_log\"] = np.log(df[\"sh_volume\"].shift(5))   # 5 days ago volume\n",
    "df[\"vol_change1\"]  = df[\"sh_volume\"].pct_change().shift(1)  # yesterday’s relative change\n",
    "\n",
    "# Drop rows with NaNs created by shifts\n",
    "df = df.dropna(subset=[\"vol_lag1_log\", \"vol_lag2_log\", \"vol_lag3_log\", \"vol_lag4_log\", \"vol_lag5_log\", \"vix_lag1\", \"vix_change\"]).reset_index(drop=True)\n",
    "\n",
    "# Re-split using the stored split_date\n",
    "train = df[df[\"date\"] < split_date].copy()\n",
    "test  = df[df[\"date\"] >= split_date].copy()\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3) DEFINE FEATURES AND TARGET\n",
    "# =====================================================\n",
    "feature_cols = [\n",
    "    \"log_vol\", \"vol_lag1_log\", \"vol_lag3_log\", \"vol_lag2_log\"\n",
    "]\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "y_train = np.log(train[\"target_5d\"])  # log-target\n",
    "X_test  = test[feature_cols]\n",
    "y_test  = np.log(test[\"target_5d\"])\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4) TUNE RANDOM FOREST\n",
    "# =====================================================\n",
    "rf = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Use time-aware cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "# Parameter grid to search\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [15, 20, 25, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "rf = best_rf\n",
    "print(\"\\nBest parameters:\", grid.best_params_)\n",
    "print(f\"Best CV RMSE: {-grid.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "# 5) EVALUATION\n",
    "# =====================================================\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# --- Log scale metrics ---\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Log scale metrics:\")\n",
    "print(f\"  RMSE (log): {rmse:.3f}\")\n",
    "print(f\"  MAE  (log): {mae:.3f}\")\n",
    "print(f\"  R²   (log): {r2:.3f}\")\n",
    "\n",
    "# --- Original scale metrics ---\n",
    "actual = np.exp(y_test)\n",
    "pred   = np.exp(y_pred)\n",
    "\n",
    "mse_orig = mean_squared_error(actual, pred)\n",
    "rmse_orig = np.sqrt(mse_orig)\n",
    "mae_orig = mean_absolute_error(actual, pred)\n",
    "mape = (np.abs(pred - actual) / actual).mean() * 100\n",
    "\n",
    "print(\"\\nOriginal scale metrics:\")\n",
    "print(f\"  RMSE: {rmse_orig:,.0f}\")\n",
    "print(f\"  MAE : {mae_orig:,.0f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6) VISUALIZATION\n",
    "# =====================================================\n",
    "# --- Actual vs Predicted (log scale) ---\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "lo, hi = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
    "plt.plot([lo, hi], [lo, hi], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual log(5-Day Volume)\")\n",
    "plt.ylabel(\"Predicted log(5-day Volume)\")\n",
    "plt.title(\"Random Forest: Actual vs Predicted (log scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Time series (original scale) ---\n",
    "plot_df = test.copy()\n",
    "plot_df[\"actual_5d_volume\"] = actual\n",
    "plot_df[\"predicted_5d_volume\"] = pred\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(plot_df[\"date\"], plot_df[\"actual_5d_volume\"], label=\"Actual\", alpha=0.85)\n",
    "plt.plot(plot_df[\"date\"], plot_df[\"predicted_5d_volume\"], label=\"Predicted\", alpha=0.85)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"5 day trading Volume\")\n",
    "plt.title(\"Random Forest: Actual vs Predicted (original scale)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Feature importance ---\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values()\n",
    "plt.figure(figsize=(6,4))\n",
    "importances.plot(kind=\"barh\")\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
