{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:56:05.712691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# ===== LSTM for Next-Day Trading Volume (from your CSVs) =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda6d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 0) Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc89925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1) Load & merge data (keep your split)\n",
    "# -----------------------------\n",
    "train = pd.read_csv(\"train_volume_vix.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"test_volume_vix.csv\",  parse_dates=[\"date\"])\n",
    "\n",
    "train = train.sort_values(\"date\").reset_index(drop=True)\n",
    "test  = test.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "split_date = test[\"date\"].min()\n",
    "df = pd.concat([train, test], ignore_index=True).sort_values(\"date\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1904299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 2) Feature engineering (no leakage)\n",
    "#    We build features that are known up to day t to predict target at t+1\n",
    "# -----------------------------\n",
    "# Basic transforms\n",
    "df[\"log_volume_t\"] = np.log(df[\"sh_volume\"])\n",
    "\n",
    "# VIX dynamics\n",
    "df[\"vix_change\"] = df[\"vix_close\"].diff()           # today's change vs yesterday\n",
    "df[\"vix_pct\"]    = df[\"vix_close\"].pct_change()\n",
    "\n",
    "\n",
    "# Drop initial NaNs from diff/pct_change\n",
    "df = df.dropna(subset=[\"vix_change\", \"vix_pct\"]).reset_index(drop=True)\n",
    "\n",
    "# Target: predict next-day volume (already provided as target_volume)\n",
    "# We'll model y_log = log(target_volume)\n",
    "df[\"y_log\"] = np.log(df[\"target_volume\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28cc8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO VIX\n",
    "# -----------------------------\n",
    "# 3) Select feature columns\n",
    "#    (sequence model learns temporal patterns; no manual lags needed)\n",
    "# -----------------------------\n",
    "feature_cols = [\"log_volume_t\"]\n",
    "\n",
    "feat_df = df[[\"date\"] + feature_cols + [\"y_log\"]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443997f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIX\n",
    "# -----------------------------\n",
    "# 3) Select feature columns\n",
    "#    (sequence model learns temporal patterns; no manual lags needed)\n",
    "# -----------------------------\n",
    "feature_cols = [\"log_volume_t\", \"vix_close\", \"vix_change\"]\n",
    "\n",
    "feat_df = df[[\"date\"] + feature_cols + [\"y_log\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a231785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 4) Split back to train/test by date\n",
    "#    (windows for earliest test targets will include history from train, which is OK)\n",
    "# -----------------------------\n",
    "train_df = feat_df[feat_df[\"date\"] < split_date].copy()\n",
    "test_df  = feat_df[feat_df[\"date\"] >= split_date].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636856db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 5) Scale features and target using train only\n",
    "# -----------------------------\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_2d = X_scaler.fit_transform(train_df[feature_cols].values)\n",
    "X_test_2d  = X_scaler.transform(test_df[feature_cols].values)\n",
    "\n",
    "y_train_1d = y_scaler.fit_transform(train_df[[\"y_log\"]].values).ravel()\n",
    "y_test_1d  = y_scaler.transform(test_df[[\"y_log\"]].values).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "569e3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: (4752, 30, 1)  | Test sequences: (501, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 6) Build sequences (rolling windows)\n",
    "#    LOOKBACK = number of past days the LSTM sees to predict t+1\n",
    "# -----------------------------\n",
    "LOOKBACK = 30  # try 30 trading days; adjust as you like\n",
    "\n",
    "def make_sequences(X_2d, y_1d, dates, lookback):\n",
    "    X_list, y_list, d_list = [], [], []\n",
    "    for i in range(lookback, len(X_2d)):\n",
    "        X_list.append(X_2d[i-lookback:i, :])   # window [i-lookback, ..., i-1]\n",
    "        y_list.append(y_1d[i])                 # target aligned at i (predict next-day log vol)\n",
    "        d_list.append(dates.iloc[i])\n",
    "    return np.array(X_list), np.array(y_list), pd.Series(d_list)\n",
    "\n",
    "# Build sequences on the FULL timeline so test windows can include train history,\n",
    "# then split sequences by their TARGET DATE (d_list) relative to split_date.\n",
    "X_all_2d = X_scaler.transform(feat_df[feature_cols].values)  # transform entire series\n",
    "y_all_1d = y_scaler.transform(feat_df[[\"y_log\"]].values).ravel()\n",
    "dates_all = feat_df[\"date\"].reset_index(drop=True)\n",
    "\n",
    "X_seq, y_seq, d_seq = make_sequences(X_all_2d, y_all_1d, dates_all, LOOKBACK)\n",
    "\n",
    "train_mask = d_seq < split_date\n",
    "test_mask  = d_seq >= split_date\n",
    "\n",
    "X_train, y_train_seq = X_seq[train_mask], y_seq[train_mask]\n",
    "X_test,  y_test_seq  = X_seq[test_mask],  y_seq[test_mask]\n",
    "dates_test_seq = d_seq[test_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Train sequences:\", X_train.shape, \" | Test sequences:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09162c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761a37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 7) Define LSTM model\n",
    "# -----------------------------\n",
    "n_features = X_train.shape[-1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(LOOKBACK, n_features)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"mse\",\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 8) Train/validation split (time-aware: last slice of train as val)\n",
    "# -----------------------------\n",
    "val_frac = 0.15\n",
    "val_size = int(len(X_train) * val_frac)\n",
    "X_tr, X_val = X_train[:-val_size], X_train[-val_size:]\n",
    "y_tr, y_val = y_train_seq[:-val_size], y_train_seq[-val_size:]\n",
    "\n",
    "hist = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edaf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 9) Inference & metrics\n",
    "#    (invert scaling to log-space, then to original volume)\n",
    "# -----------------------------\n",
    "# Predict (scaled y)\n",
    "y_pred_scaled = model.predict(X_test).ravel()\n",
    "\n",
    "# Back to log scale\n",
    "y_pred_log = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_log = y_scaler.inverse_transform(y_test_seq.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Back to original scale\n",
    "pred = np.exp(y_pred_log)\n",
    "actual = np.exp(y_test_log)\n",
    "\n",
    "# Metrics\n",
    "mse_log = mean_squared_error(y_test_log, y_pred_log)\n",
    "rmse_log = np.sqrt(mse_log)\n",
    "mae_log = mean_absolute_error(y_test_log, y_pred_log)\n",
    "r2_log = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "mse_orig = mean_squared_error(actual, pred)\n",
    "rmse_orig = np.sqrt(mse_orig)\n",
    "mae_orig = mean_absolute_error(actual, pred)\n",
    "mape = (np.abs(pred - actual) / actual).mean() * 100\n",
    "\n",
    "print(\"\\n=== LSTM Performance ===\")\n",
    "print(f\"Log scale -> RMSE: {rmse_log:.4f}  MAE: {mae_log:.4f}  RÂ²: {r2_log:.3f}\")\n",
    "print(f\"Original  -> RMSE: {rmse_orig:,.0f}  MAE: {mae_orig:,.0f}  MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 10) Plots\n",
    "# -----------------------------\n",
    "# Loss curve\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist.history[\"loss\"], label=\"train\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"MSE (scaled)\")\n",
    "plt.title(\"Training History\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Actual vs Predicted (log scale)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test_log, y_pred_log, alpha=0.6)\n",
    "lo, hi = min(y_test_log.min(), y_pred_log.min()), max(y_test_log.max(), y_pred_log.max())\n",
    "plt.plot([lo, hi], [lo, hi], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual log(Next-Day Volume)\")\n",
    "plt.ylabel(\"Predicted log(Next-Day Volume)\")\n",
    "plt.title(\"LSTM: Actual vs Predicted (log scale)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Time series (original scale)\n",
    "plot_df = pd.DataFrame({\n",
    "    \"date\": dates_test_seq,\n",
    "    \"actual_volume\": actual,\n",
    "    \"predicted_volume\": pred\n",
    "})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(plot_df[\"date\"], plot_df[\"actual_volume\"], label=\"Actual\", alpha=0.85)\n",
    "plt.plot(plot_df[\"date\"], plot_df[\"predicted_volume\"], label=\"Predicted\", alpha=0.85)\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Trading Volume\")\n",
    "plt.title(\"LSTM: Actual vs Predicted (original scale)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
