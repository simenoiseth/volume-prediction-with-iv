{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LSTM for 5-Day Accumulated Volume (Using Your CSVs) =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, callbacks\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load & merge data\n",
    "# -----------------------------\n",
    "train = pd.read_csv(\"5_21_train.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"5_21_test.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "train = train.sort_values(\"date\").reset_index(drop=True)\n",
    "test  = test.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "split_date = test[\"date\"].min()\n",
    "df = pd.concat([train, test], ignore_index=True).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Features (log volume + VIX features for later use)\n",
    "# -----------------------------\n",
    "df[\"log_vol\"] = np.log(df[\"total_dollar_volume\"])\n",
    "\n",
    "# VIX features (computed but NOT included in feature_cols yet)\n",
    "df[\"vix_lag1\"] = df[\"vix_close\"].shift(1)\n",
    "df[\"vix_change\"] = df[\"vix_close\"] - df[\"vix_lag1\"]\n",
    "df[\"vix_5d_ma\"] = df[\"vix_close\"].rolling(window=5).mean()\n",
    "\n",
    "# Target (already in your CSV)\n",
    "df[\"y_log\"] = np.log(df[\"target_5d\"])\n",
    "\n",
    "# Drop rows with NaN in any relevant fields\n",
    "df = df.dropna(subset=[\"log_vol\", \"y_log\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train/Test split by date\n",
    "# -----------------------------\n",
    "start_date = pd.Timestamp(\"2020-03-01\")\n",
    "df = df[df[\"date\"] >= start_date].reset_index(drop=True)\n",
    "\n",
    "# Re-split using the stored split_date\n",
    "train_df = df[df[\"date\"] < split_date].copy()\n",
    "test_df  = df[df[\"date\"] >= split_date].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Active feature columns\n",
    "# -----------------------------\n",
    "feature_cols = [\"log_vol\"]\n",
    "\n",
    "df = df.dropna(subset=feature_cols).reset_index(drop=True)\n",
    "\n",
    "# Scale features and target using TRAIN only\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_2d = X_scaler.fit_transform(train_df[feature_cols])\n",
    "X_test_2d  = X_scaler.transform(test_df[feature_cols])\n",
    "\n",
    "y_train_1d = y_scaler.fit_transform(train_df[[\"y_log\"]]).ravel()\n",
    "y_test_1d  = y_scaler.transform(test_df[[\"y_log\"]]).ravel()\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Build sequences\n",
    "# -----------------------------\n",
    "LOOKBACK = 30\n",
    "\n",
    "def make_sequences(X, y, dates, lookback):\n",
    "    X_list, y_list, d_list = [], [], []\n",
    "    for i in range(lookback, len(X)):\n",
    "        X_list.append(X[i-lookback:i, :])\n",
    "        y_list.append(y[i])\n",
    "        d_list.append(dates.iloc[i])\n",
    "    return np.array(X_list), np.array(y_list), pd.Series(d_list)\n",
    "\n",
    "# Use FULL data so test windows can include train history\n",
    "X_all = X_scaler.transform(df[feature_cols])\n",
    "y_all = y_scaler.transform(df[[\"y_log\"]]).ravel()\n",
    "dates_all = df[\"date\"].reset_index(drop=True)\n",
    "\n",
    "X_seq, y_seq, d_seq = make_sequences(X_all, y_all, dates_all, LOOKBACK)\n",
    "\n",
    "train_mask = d_seq < split_date\n",
    "test_mask  = d_seq >= split_date\n",
    "\n",
    "X_train, y_train_seq = X_seq[train_mask], y_seq[train_mask]\n",
    "X_test,  y_test_seq  = X_seq[test_mask],  y_seq[test_mask]\n",
    "dates_test_seq = d_seq[test_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Train sequences:\", X_train.shape, \" | Test sequences:\", X_test.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) LSTM model\n",
    "# -----------------------------\n",
    "n_features = X_train.shape[-1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(LOOKBACK, n_features)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Train with time-aware split\n",
    "# -----------------------------\n",
    "val_size = int(len(X_train) * 0.15)\n",
    "X_tr, X_val = X_train[:-val_size], X_train[-val_size:]\n",
    "y_tr, y_val = y_train_seq[:-val_size], y_train_seq[-val_size:]\n",
    "\n",
    "hist = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Evaluation\n",
    "# -----------------------------\n",
    "y_pred_scaled = model.predict(X_test).ravel()\n",
    "\n",
    "# back-transform\n",
    "y_pred_log = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()\n",
    "y_test_log = y_scaler.inverse_transform(y_test_seq.reshape(-1,1)).ravel()\n",
    "\n",
    "pred = np.exp(y_pred_log)\n",
    "actual = np.exp(y_test_log)\n",
    "\n",
    "print(\"\\n=== 5-Day LSTM Performance ===\")\n",
    "print(\"RMSE (log):\", np.sqrt(mean_squared_error(y_test_log, y_pred_log)))\n",
    "print(\"MAE  (log):\", mean_absolute_error(y_test_log, y_pred_log))\n",
    "print(\"RÂ²   (log):\", r2_score(y_test_log, y_pred_log))\n",
    "\n",
    "print(\"\\nOriginal scale:\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(actual, pred)))\n",
    "print(\"MAE :\", mean_absolute_error(actual, pred))\n",
    "print(\"MAPE:\", (np.abs(pred - actual) / actual).mean() * 100)\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Plots\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist.history[\"loss\"], label=\"train\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Training Loss (5-day LSTM)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test_log, y_pred_log, alpha=0.6)\n",
    "lo, hi = min(y_test_log.min(), y_pred_log.min()), max(y_test_log.max(), y_pred_log.max())\n",
    "plt.plot([lo,hi],[lo,hi],'r--')\n",
    "plt.xlabel(\"Actual log(target_5d)\")\n",
    "plt.ylabel(\"Predicted log(target_5d)\")\n",
    "plt.title(\"Actual vs Predicted (log scale)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ts_df = pd.DataFrame({\n",
    "    \"date\": dates_test_seq,\n",
    "    \"actual_5d\": actual,\n",
    "    \"pred_5d\": pred\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ts_df[\"date\"], ts_df[\"actual_5d\"], label=\"Actual\", alpha=0.85)\n",
    "plt.plot(ts_df[\"date\"], ts_df[\"pred_5d\"], label=\"Predicted\", alpha=0.85)\n",
    "plt.title(\"5-Day Accumulated Volume Prediction\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
