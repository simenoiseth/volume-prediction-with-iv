{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fab1837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 10:15:39.427965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import set_seed, read_and_merge, build_features_nextday, split_by_date, fit_transform_scalers, make_sequences_generic, time_aware_train_val_split\n",
    "from model_utils import build_lstm, train\n",
    "from eval_utils import regression_report_log_and_orig, plot_history, scatter_actual_vs_pred, plot_timeseries\n",
    "import numpy as np\n",
    "\n",
    "WINDOW = 10; BATCH_SIZE = 64; EPOCHS = 20; LR = 1e-3; SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "# 1) Load data\n",
    "df, split_date = read_and_merge(\"train_volume_vix.csv\", \"test_volume_vix.csv\")\n",
    "\n",
    "\n",
    "# 2) Build only volume-based features (ignore VIX columns)\n",
    "df = df.copy()\n",
    "df[\"log_volume_t\"] = np.log(df[\"sh_volume\"])\n",
    "df[\"y_log\"] = np.log(df[\"target_volume\"])\n",
    "df = df.dropna(subset=[\"log_volume_t\", \"y_log\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3) Split & scale\n",
    "train_df, test_df = split_by_date(df, split_date)\n",
    "feature_cols = [\"log_volume_t\"]\n",
    "train_s, test_s, scaler = fit_transform_scalers(train_df, test_df, feature_cols)\n",
    "\n",
    "\n",
    "# 4) Build sequences\n",
    "X_train, y_train, _ = make_sequences_generic(train_s, WINDOW, feature_cols)\n",
    "X_test, y_test, idx_test = make_sequences_generic(test_s, WINDOW, feature_cols)\n",
    "X_tr, y_tr, X_val, y_val = time_aware_train_val_split(X_train, y_train, val_frac=0.15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82019c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train mean: 22.915747 std: 0.19423154\n",
      "Example target values: [22.471537 22.543764 22.618963 22.508448 22.531769 22.550158 22.565903\n",
      " 22.448582 22.471306 22.512892]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train mean:\", y_train.mean(), \"std:\", y_train.std())\n",
    "print(\"Example target values:\", y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) Model\n",
    "model = build_lstm(WINDOW, n_features=len(feature_cols), lr=LR)\n",
    "hist = train(model, X_tr, y_tr, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# 6) Evaluate\n",
    "y_pred_log = model.predict(X_test).ravel()\n",
    "report = regression_report_log_and_orig(y_test, y_pred_log)\n",
    "print(report)\n",
    "\n",
    "\n",
    "# 7) Plots\n",
    "plot_history(hist, title=\"Training History — Next-day (No VIX)\")\n",
    "scatter_actual_vs_pred(y_test, y_pred_log, title=\"Next-day (No VIX) — Actual vs Pred (log)\")\n",
    "plot_timeseries(idx_test, np.exp(y_test), np.exp(y_pred_log), ylabel=\"Next-day volume\", title=\"Next-day (No VIX) — Original scale\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
